\section{Instance-based learning}\label{sec:theoryInstanceLearning}
Instance-based learning is a set of algorithms within data mining and machine learning and is often referred to as lazy classification.
In the training phase the algorithms do not require much work since it is being trained on already stored instances.
\cite[p. 78]{DataMiningPractical2011} 

\bigskip

The real work is done when a new instance is being classified.
This new instance is compared to all other, already stored, instances. 
The comparison between a new instance and the stored ones is being classified with a distance metric, where the closest, already stored, instance is used to assign a class to the new one.
This classification method is called nearest-neighbour classification, and when being compared to \textit{k} neighbours it's called k-nearest-neighbour.
\cite[p. 78]{DataMiningPractical2011} 

\bigskip

\mt{With instance-based learning, new examples can be inserted into the training set at any time, which is possible thanks to the low training time of the algorithm.
This means that the set easily can be extended with new data as the number of data points increases.
\cite[p. 135]{DataMiningPractical2011}}


\subsection{K-Nearest Neighbour}\label{sec:theoryUnClassKnn}
In \acrfull{knn} classification a data instance is being compared to a set $k$ of its nearest neighbours.
These neighbours are like in general instance-based learning previously stored instance that are being used to compare against.
The method is perfectly suited when this new instance needs to be classified \cite[p. 77-79]{DataMiningPractical2011}

\bigskip

If a set of  numeric values is compared, the computation of the distance between the two points are trivial. 
It only computes the difference between these two values.
With two or more values the computation is almost as straightforward.
In these cases, the Euclidean Distance method (which is the default) is used to make the computation and comparison of the values.
An important part is that the data need to be normalized and of equally importance.
One of the problems in the learning phase is to determine the important values.
\cite[p. 77-79]{DataMiningPractical2011}

\bigskip

\Cref{fig:knnIllustration} illustrates a representation when a new instance is being classified into an already existing set or area.
The green and red dots are already existing instanced, and the blue dot is new and is going to be classified.
In this case the new instance is going to be classified as red, if $k=3$.

\fig{K-NN classification of a new instance where $k=3$}{knnIllustration}{0.3}{knnClassification}
